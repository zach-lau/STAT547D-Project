\documentclass[11pt]{article}
\usepackage{amsmath, amsthm}
\usepackage{shortex}
\usepackage{csvsimple}
\usepackage[margin=1in]{geometry}
\graphicspath{{results}}

\bibliographystyle{plain}

\author{Zachary Lau}
\title{GP-Ouroboros: Using Gaussian Processes to model the log marginal
likelihood in Bayesian hyperparameter Inference for Gaussian Processes}

\begin{document}
\maketitle
\begin{abstract}
Markov Chain Monte Carlo (MCMC) methods are particularly useful for estimating
expectations in higher-dimensional parameter spaces. However, these algorithms
may not be practical when the likelihood is very expensive to evaluate. This
problem can occur in Bayesian inference on the hyperparameters of large Gaussian
Processes (GP).  One alternative which has been proposed for expensive likelihoods
is to use the posterior mean of a Gaussian Process to model the log-likelihood
or log posterior.  However, just using the mean ignores the variance term also
provided by GPs. We explore two alternative ways of incorporating this
variance term; firstly by incorporating it in the mean of a log normal
distribution (we call this the adjusted mean), and secondly by sampling
gradients instead of evaluating them deterministically.  Our experimental and
theoretical results show that neither method is entirely satisfactory. The
adjusted mean target displays unhelpful boundary seeking behaviour, while
directly sampling gradients turns out to be theoretically unsound. We hope that
in the future the failure of these algorithms can be learned from so that we can
properly account for uncertainty in stochastic surrogate modelling of the
log-likelihood for Bayesian inference.  \end{abstract}

\section{Introduction and Background}
\subsection{Likelihood free and surrogate likelihood methods}
The challenge of performing Bayesian inference with intractable or expensive
likelihood functions has been approached from multiple directions in the past.
Rasmussen \cite{rasmussen2003gaussian} suggests making proposals using HMC
applied to a surrogate model of the log posterior and then performing a Metropolis-Hastings
accept-reject with evaluations of the true likelihood. However, it is not
clear that this scheme has the correct stationary distribution. Christen \& Fox
\cite{Christen01122005} introduced delayed acceptance MCMC which similarly
makes proposals using a surrogate, but uses a pre-screening step to ensure that
the chain targets the correct distribution. On the other hand, likelihood free
approaches attempt to perform bayesian inference when the likelihood function
is not available or tractable, but simulations can be made from the data
generating process. One such framework is Approximate Bayesian Computation
(ABC) \cite{beaumont2019approximate}. More recently Gutmann \& Corander 
\cite{JMLR:v17:15-017} have considered applying Bayesian optimization to improve
simulation efficiency. Finally Stuart et al. \cite{stuart2018posterior} discuss
error bounds on the distance between the true posterior and a Gaussian Process
approximation of the posterior in terms of Hellinger distance. Our work differs
from that of Rasmussen and Christen \& Fox in that we focus on sampling directly
from the surrogate model without a correction step. Furthermore, it differs from
ABC and likelihood free methods in that the surrogate model is based on true
evaluations of the likelihood.
% TODO - comparison with ABC
\subsection{Gaussian Processes}
Gaussian processes (GP) modelling (see \cite{rasmussen2006gaussian}) is a type of non-parametric Bayesian modelling. It can
be viewed as placing a Gaussian process prior on a function, i.e. observations 
$y_1, y_2, \ldots, y_n$ at any finite set of input points $x_1, x_2, \ldots x_n$
are distributed according to a multivariate normal distribution. Such a prior is fully specified by a mean function
$\mu(x)$ and the covariance function $k(x,x')$. Given a set of training points
$x_1, \ldots, x_n$, inference at a set of test points $x'_1, \ldots, x'_m$ is
found by computing the conditional distribution of $y_1', \ldots,  y'_m$ given 
$y_1, \ldots, y_n$. The resulting posterior distribution sees
$[y'_1, \ldots, y'_m]^\top \sim \Norm(\mu', K')$ where $\mu'$ and $K'$ are
given by the inference equations 
\begin{align}
    \mu' &= \mu + k^\ast (K+\sigma^2 I)^{-1} \vec y \\
    K' &= k^{\ast\ast} - k^\ast (K + \sigma^2 I)^{-1} k^{\ast\top}
\end{align}
Where $\mu$ represents the prior mean, $k^{\ast\ast}_{ij} = k(x'_i, x'_j)$ 
gives the prior covariance, $k^\ast_{ij} = k(x'_i, x_j)$ the cross-covariance,
$\vec y$ the vector of observations, and $\sigma^2$ represents \iid
observational noise. Even when there is no noise, a small amount of noise may be
included for numerical stability of the inverse. An important feature of
Gaussian process modelling is that in addition to giving estimates at new test
points through the posterior mean, it also quantifies uncertainty through
the posterior covariance.

We will consider GPs from two perspectives. Firstly, Bayesian
hyperparameter inference in GPs provides a good test case where the likelihood
evaluation can be prohibitive. Secondly GPs can themselves be used as a
surrogate model for the likelihood that quantifies uncertainty at unobserved
locations.

\subsection{Hyper-parameter inference for Gaussian Processes}
Typically the covariance function used for GP inference belongs to a parametric
family. For example, the squared-exponential family in one-dimension has the form
$k(x,x') = \sigma_f^2 \exp\left(-\frac 1 2 \left( \frac{x-x'}{\ell} \right)^2 \right)$
with hyperparameters $\sigma^2_f$ and $\ell$. It is most common to choose these
parameters given the data by maximizing the so-called log-marginal likelihood,
i.e. the likelihood of the observations after marginalizing over the unobserved
latent function. With observation noise, this function becomes
\begin{align}
    l(\theta) &= -\frac 1 2 y ^\top (K + \sigma^2 I)^{-1} y - \frac 1 2 \log |K+\sigma^2 I| 
    - \frac n 2 \log(2\pi)
\end{align}

An alternative to using MLE is to place a prior over the hyperparameters, and
then perform inference by averaging over the hyperparameter posterior. Our target
then becomes
\begin{align}
    \log p(\theta|y) &= \log p(\theta ) -\frac 1 2 y ^\top (K + \sigma^2 I)^{-1} y - \frac 1 2 \log |K+\sigma^2 I| 
    - \frac n 2 \log(2\pi)
\end{align}
Some of the major challenges with sampling from such a distribution include
multi-modality and the computational cost of computing matrix solves and
determinants. The latter can be a particular challenge in the case of GPs with
large numbers of observations, particularly since their cost scales as 
$O(n^3)$.

\section{Algorithms}
\subsection{Set up and motivation}
Consider a Bayesian inference problem with an expensive likelihood such as the GP
problem described above. The first premise of this work, whose validity may be explored
in future work, is that in the expensive likelihood regime, Bayesian inference
should be separated into two parts
\begin{itemize}
    \item \emph{Likelihood model building}: judicious evaluations of the
    likelihood function to provide the most useful understanding of the
    likelihood function
    \item \emph{Sampling}: Generation of samples from the posterior implied
    \emph{by our model}
\end{itemize}

% In this work we focus on the second phase, leaving to future work the 
% evaluation of the first. Concretely, suppose that we have some pre-existing set
% of log-likelihood evaluations $l(\theta_1), \ldots, l(\theta_m)$
% (hopefully judiciously chosen). We construct a a GP model of the function 
% $l$ over the parameter space, call this model $\mathcal M$. Our work here
% explores the problem of sampling from $\theta$ given a model of its likelihood
% \emph{that incorporates uncertainty}.

\subsection{Mean estimation}
The most obvious way to sample from the GP surrogate model is
to use the posterior mean as the log likelihood. That is, if the posterior mean
is given by $\mu(\theta)$ we take $\hat l(\theta) = \mu(\theta)$ so that the
likelihood is given by
$\mathcal L(\theta) = \exp(\mu(\theta))$. Another method is to consider the posterior
mean of $f$ itself. Note that $f(\theta)$ is marginally log-normal so it has
expectation
$\E f(\theta) = \exp\left(\mu(\theta) + \frac 1 2 \sigma^2(\theta) \right)$,
giving log-likelihood $\hat l(\theta) = \mu(\theta) + \frac 1 2 \sigma^2 (\theta)$.
This second estimate takes into account uncertainty, but only insofar as it
affects the mean. The posteriors arising from such likelihoods can be
targeted using off the shelf samplers like NUTS \cite{hoffman2011nouturnsampleradaptivelysetting}.

\subsection{Uncorrected Langevin Dynamics}
The third method we propose to analyze involves taking \emph{samples} from the
gradient instead of using a fixed surrogate model in order to reflect
uncertainty in the surrogate model. Importantly, we note that the gradient of a
GP and the function itself are jointly still a GP, so sampling amounts to
sampling from a GP posterior. We restrict ourselves to uncorrected Langevin
dynamics because this requires only a single sample of the gradient. Sampling
a longer HMC trajectory would be significantly more expensive because each
gradient sample would need to be taken conditional on the previous samples. With
sample $i$ requiring a roughly $O(i^2)$ block matrix update to the inverse, the
total trajectory cost would be roughly $O(L^3)$. On the other hand, given a
precomputed inverse that is shared amongst all points, a single
Langevin step with a model built on $m$ true evaluations requires only a 
single $O(m^2)$ matrix multiplication.

\subsection{Theoretical accuracy}
As discussed in \cite{stuart2018posterior}, the theoretical optimum model, in
the sense of Hellinger distance, to sample from would be the \emph{joint}
distribution over $f$ and $\theta$, i.e. the model defined by the following
generative process.  \begin{align} \log f &\sim \mathcal{GP}\\ \theta &\sim
\frac{p_0(\theta)f(\theta)}{\mathcal Z(f)} \end{align} Unfortunately, sampling
from this joint distribution is a difficult problem that our proposed methods
only approximate in the well informed case.

Firstly, we consider our Langevin dynamics inspired sampler. This can be seen as
an approximate Metropolis-within-Gibbs sampler where the marginal $f | \theta$
is approximated by the $GP$ posterior but \emph{not conditioned on $\theta$}.
A true conditional update of $f$ would need to preserve (see derivation in Appendix)
\begin{align}
    p(f|\theta) &= \frac{p(f, \theta)}{p(\theta)} \\
    &\propto \frac{p(f)f(\theta)}{\mathcal Z(f)}
\end{align}

On the other hand, if we approximate $\mathcal Z(f)$ as a constant, we recover
the log mean sampler $\hat l(\theta) = \mu(\theta) + \frac 1 2 \sigma^2 (\theta)$.
To see this, note that integrating our joint distribution over $f$ we find
\begin{align}
    p(\theta) &= \int p(f, \theta) df \\
    & \propto \int p_0(\theta)f(\theta)p(f) df \\
    &= p_0(\theta)\E f(\theta) \\
    &= p_0(\theta)\exp\left(\mu(\theta) + \frac 1 2 \sigma^2(\theta)\right)
\end{align}

Thus none of our samplers targets the ``correct'' stationary distribution, with
the former not accounting for the $f(\theta)$ or $\mathcal Z(f)$ term, and the
latter failing to account for the $\mathcal Z(f)$ term.

% However, we note that heuristically given more
% evaluations of the true likelihood (and hence less variane in our model) these
% constant approximations will be approximately true as the influence of any
% one sample diminishes.

% This gives joint distribution $p(f, \theta) = \frac{p_0(\theta)f(\theta)M(f)}{\mathcal Z(f)}$.
% Our challenge is to sample from the marginal distribution of $\theta$.
% At this point we make a few remarks to justify our choice of model, and
% highlight the complexity of the problem.

% \begin{remark}
%     Directly modelling the likelhood as opposed to the log-likelihood would not
%     give a valid likelihood function.
% \end{remark}

% Since the normal distribution has infinite support, such a model would have a
% non-zero probability of drawing a negative likelihood.

% \begin{remark}
%     Using the GP mean as a surrogate model ignores the normalizing constant
%     $\mathcal Z(f)$
% \end{remark}

% There are two problems with using the GP mean as a surrogate model. Firstly,
% the motivation is flawed since $f$ is log-normal, and secondly as seen from
% the generative model above it ignores the effect of the normalizing constant.

\section{Experiments}
Each method (GP mean, adjusted mean, sampled gradients) was tested on the Cartesian product of $n \in \{10, 100, 1000\}$, $d \in \{1, 5,
50\}$ and $m \in \{10, 100\}$ where $n$ is the number of observations in the
base model, $d$ the dimensionality of the base model and $m$ the number of
likelihood evaluations used to build the surrogate model. The surrogate model
was built on random evaluations uniformly chosen in our parameter space. For $n \in \{10, 100\}$ the results
were compared to a posterior sample computed using the true log-likelihood, but
this was prohibitive for $n=1000$. Implementation was in Python and used    
Stan \cite{standevstancore} for NUTS. Full code, results and details of the
experiments can be found on
\href{https://github.com/zach-lau/STAT547D-Project}{Github}
\footnote{https://github.com/zach-lau/STAT547D-Project}. The Langevin
sampler behaves overall poorly. This is not surprising in high dimensions given
its local behaviour, however even in moderate dimension ($d=5$) it displays
pathological behaviour (see Figure \ref{fig:pair}). This may be explained by the
fact that it does not target the correct joint distribution. The most
interesting result from the adjusted mean sampler is its occasional boundary seeking
behaviour (see Figure \ref{fig:adjusted_explanation}). The long right-tail of the
log-normal distribution encourages it to sample from areas of high-variance even
when this is of detriment to its qualitative results. We hypothesize that this
is related to the target's failure to account for the normalizing factor $\mathcal
Z(f)$ which tempers the strength of the upper tail. Overall the mean-model
performs decently, displaying few pathological behaviours. It could likely be
improved by more judicious choices of likelihood evaluations. This is a possible
future area of research.

\section{Conclusion}
In this project we provide a renewed exploration of the idea of using stochastic
surrogate models of the likelihood function in Bayesian inference, particularly
with a focus on Bayesian inference for Gaussian process hyperparameter learning.
We propose two basic algorithms to incorporate uncertainty: incorporating it
through the mean of a log-normal or through sampling. While both methods have
experimental and theoretical shortfalls, we hope this opens the door for future
research on understanding how surrogate models which quantify uncertainty can
be used in Bayesian inference. In particular, another promising area of research
we have not yet explored is how to acquire the log-likelihood evaluations used to
build the surrogate model in the first place.

% Specifically we envision two areas of future
% research. Firstly, in a similar vein to that discussed in this project, future
% work may include analysis of new algorithms and stochastic surrogate models
% where targetting the joint distribution over the model and the inference
% paramter becomes feasible.  A second future vein which has not been explored by
% this work includes exploiting surrogate models' measures of uncertainty to guide
% future true likelihood evaluations in a manner similar to Bayesian optimization
% and active learning.

\bibliography{references}

\appendix
\section{Target conditional}
Given our generative model, we get joint distribution
\begin{align}
    p(f, \theta) &= p(f)\frac{p_0(\theta)f(\theta)}{\mathcal Z(f)}
\end{align}
Where the normalizing constant
$\mathcal Z(f) = \int p_0(\theta)f(\theta) d\theta$.
This gives the $\theta$ marginal as
\begin{align}
    p(\theta) &= \int p(f) \frac{p_0(\theta)f(\theta)}{\mathcal Z(f)} df \\
    &= p_0(\theta)  \int p(f) \frac{f(\theta)}{\mathcal Z(f)} df
\end{align}
The conditional distribution of $f|\theta$ is given by
\begin{align}
    p(f | \theta) \propto \frac{p(f)f(\theta)}{\mathcal Z(f)}
\end{align}
Intuitively this skews $f$ higher at the current value of $\theta$, but this
scaling is tempered by the subsequent increase in the normalizing constant.

% If
% we assume that $\mathcal Z(f)$ is relatively constant, then sampling
% $f(\theta) | \theta$ corresponds to sampling from
% $p(y) \propto y \log \Norm(\mu, \sigma^2)$ which corresponds to the tilted
% log normal $\log \Norm(\mu + \sigma^2, \sigma^2)$.

\section{Algorithms}
Algorithm \ref{alg:unadjusted} is used for uncorrected
Langevin dynamics using GP sampled gradients. In implementation step size is
scaled down proportional to the standard deviation of observed log-likelihoods.
\begin{algorithm}
\caption{Unadjusted Langevin for GP Likelihood}
\label{alg:unadjusted}
\begin{algorithmic}
    \Require Stepsize $\tau$, Iterations $N$
    \State Compute $K$ the covariance amongst train points
    \State $Ki \gets (K+\sigma^2 I)^{-1}$
    \State Initialize $\theta \sim p_0(\theta)$
    \For{$i=0$ to N}
        % \State $k^\ast \gets$ cross covariance of gradients with train points
        % \State $k^{\ast\ast} \gets$ covariance of test points
        % \State $kKi \gets k^{\ast\top} Ki$
        % \State $\mu \gets kKi y$
        % \State $k \gets k^{\ast\ast} - k^\ast (K + \sigma^2 I) k^{\ast\top}$
        \State Sample $\nabla \log f (\theta)$ from GP model
        \State Sample $\xi \sim \Norm(0,1)$
        \State $\theta \gets \theta + \tau \grad\log f(\theta) + \sqrt{2\tau} \xi$
        \State Save $\theta$
    \EndFor
\end{algorithmic}
\end{algorithm}

\section{Figures and Tables}
% General behaviour not that bad

\begin{figure}[H]
    \centering 
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/adjusted/pairs.png}
        \caption{Adjusted mean}
        \label{fig:pair_adjusted}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/gold/pairs.png}
        \caption{``True'' likelihood}
        \label{fig:pair_gold}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/langevin/pairs.png}
        \caption{Langevin}
        \label{fig:pair_langevin}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/mean/pairs.png}
        \caption{GP Mean}
        \label{fig:pair_mean}
    \end{subfigure}
    \caption{Pair plots for different methods of sampling from GP surrogate
    model where the base model has $n=10$ observations in $d=5$ dimensions and
    the surrogate log-likelihood model is built on $m=100$ likelihood
    evaluations. We can see the boundary seeking behaviour inherent in using the
    adjusted mean sampler. Furthermore the Langevin dynamics based sampler
    displays a combination of poor mixing and bizarrely invents multimodality.
    Note that due to the $O(n^3)$ cost of evaluating the true likelihood and
    $O(m^2)$ of evaluating the surrogate it may sometimes make sense to have $m
    > n$, although this particular example is somewhat unrealistic.}
    \label{fig:pair}
\end{figure}

% Traceplots

\begin{figure}[H]
    \centering
    
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/adjusted/trace.png}
        \caption{Adjusted mean}
        \label{fig:trace_adjusted}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/gold/trace.png}
        \caption{``True'' likelihood}
        \label{fig:trace_gold}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/langevin/trace.png}
        \caption{Langevin}
        \label{fig:trace_langevin}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-5-100-123/mean/trace.png}
        \caption{GP Mean}
        \label{fig:trace_mean}
    \end{subfigure}
    \caption{Traceplots and marginals of different algorithms for sampling
    from GP surrogate with $n=10$, $d=5$ and surrogate model based on $m=100$.}
    \label{fig:trace}
\end{figure}

%Summary stats
\begin{table}[htbp]
\centering
\begin{tabular}{lrrrrrrrrr}
\toprule
Parameter & mean & sd & hdi\_3\% & hdi\_97\% & mcse\_mean & mcse\_sd & ess\_bulk & ess\_tail & r\_hat \\
\midrule
theta[0] & -0.01 & 1.00 & -1.92 & 1.84 & 0.01 & 0.01 & 23649.0 & 20483.0 & 1.00 \\
theta[1] & -2.33 & 4.30 & -5.00 & 4.99 & 2.12 & 1.16 & 7.0 & 26.0 & 1.60 \\
theta[2] & -0.17 & 4.84 & -5.00 & 4.99 & 2.40 & 0.12 & 6.0 & 91.0 & 1.76 \\
theta[3] & 4.76 & 1.02 & 4.79 & 5.00 & 0.26 & 0.64 & 23.0 & 23.0 & 1.11 \\
theta[4] & 2.68 & 3.96 & -4.96 & 5.00 & 1.88 & 1.24 & 7.0 & 23.0 & 1.53 \\
theta[5] & 0.56 & 2.66 & -2.26 & 5.00 & 1.32 & 0.72 & 5.0 & 23.0 & 2.42 \\
\bottomrule
\end{tabular}
\caption{Posterior summary statistics for adjusted mean target sampled
with NUTS. Boundary effects
induce multi-modality which makes this problem particularly hard to deal with
for the sampler, as reflected in the low ESS and high Rhat for many variables.}
\label{tab:adjusted}
\end{table}

\begin{table}[htbp]
\centering
\begin{tabular}{lrrrrrrrrr}
\toprule
Parameter & mean & sd & hdi\_3\% & hdi\_97\% & mcse\_mean & mcse\_sd & ess\_bulk & ess\_tail & r\_hat \\
\midrule
theta[0] & -0.10 & 1.03 & -1.79 & 1.97 & 0.15 & 0.07 & 49.0 & 101.0 & 1.05 \\
theta[1] & 3.52 & 2.23 & -0.85 & 5.00 & 1.07 & 0.61 & 7.0 & 33.0 & 1.53 \\
theta[2] & 2.03 & 1.77 & -1.45 & 4.44 & 0.76 & 0.36 & 8.0 & 73.0 & 1.51 \\
theta[3] & 2.43 & 1.84 & -1.21 & 4.47 & 0.84 & 0.46 & 7.0 & 32.0 & 1.52 \\
theta[4] & 1.16 & 1.22 & -1.43 & 3.32 & 0.39 & 0.16 & 11.0 & 42.0 & 1.29 \\
theta[5] & -2.27 & 4.22 & -5.00 & 4.89 & 2.02 & 1.04 & 7.0 & 42.0 & 1.50 \\
\bottomrule
\end{tabular}
\caption{Posterior summary statistics with GP sampled gradients. Mixing is poor
due to random walk behaviour.}
\label{tab:sampled}
\end{table}

\
% Boundary seeking behaviour of adjusted
\begin{figure}[h]
    \centering
    
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-1-10-123/mean.png}
        \caption{GP mean of surrogate model}
        \label{fig:mean}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-1-10-123/sd.png}
        \caption{Standard deviation of surrogate model}
        \label{fig:sd}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-1-10-123/logmean.png}
        \caption{Adjusted mean of surrogate model}
        \label{fig:logmean}
    \end{subfigure}
    \begin{subfigure}{0.4\textwidth}
        \centering
        \includegraphics[width=\linewidth]{10-1-10-123/adjusted/pairs.png}
        \caption{Samples taken with NUTS}
        \label{fig:boundary_pairs}
    \end{subfigure}
    \caption{The GP mean and standard deviation for a surrogate model of the
    likelihood for a base model with $n=10$ observations in $d=1$ dimension with
    $m=10$ likelihood evaluations. The likelihood evaluations used to build
    the surrogate model are shown in red. The effective likelihood has higher
    density in both areas of higher mean and standard deviation. The sample on
    the right targets the posterior arising from using the adjusted mean likelihood
    with a standard normal prior.}
    \label{fig:adjusted_explanation}
\end{figure}

\end{document}